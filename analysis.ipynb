{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model used = SCHOLAR, SCHOLAR + BAT; K = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from run_scholar import print_top_words\n",
    "import scipy\n",
    "import torch\n",
    "import pickle\n",
    "import file_handling as fh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_20ng = 'data/20ng-prodlda/replicated/dev/'\n",
    "data_path_wiki = 'data/wikitext/processed/new-dev/'\n",
    "data_path_imdb = 'data/imdb/processed-dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_and_std_npmi(model_path):\n",
    "    d = pd.read_csv(model_path + 'dev_metrics.csv')\n",
    "    print(str(np.mean(d['npmi_value'])) + ' (' + str(np.std(d['npmi_value'])) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_baseline_20ng = 'output_20NG_vanilla-scholar_k-50/'\n",
    "model_path_baseline_wiki = 'output_wiki_vanilla-scholar_k-50/'\n",
    "model_path_baseline_imdb = 'output_imdb_vanilla-scholar_k-50/'\n",
    "\n",
    "model_path_kd_20ng = 'output_20NG_scholar-kd_k-50/'\n",
    "model_path_kd_wiki = 'output_wiki_scholar-kd_k-50/'\n",
    "model_path_kd_imdb = 'output_imdb_scholar-kd_k-50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('20NG Baseline')\n",
    "print_mean_and_std_npmi(model_path_baseline_20ng)\n",
    "print('')\n",
    "print('20NG KD')\n",
    "print_mean_and_std_npmi(model_path_kd_20ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Wiki Baseline')\n",
    "print_mean_and_std_npmi(model_path_baseline_wiki)\n",
    "print('')\n",
    "print('Wiki KD')\n",
    "print_mean_and_std_npmi(model_path_kd_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('imdb Baseline')\n",
    "print_mean_and_std_npmi(model_path_baseline_imdb)\n",
    "print('')\n",
    "print('imdb KD')\n",
    "print_mean_and_std_npmi(model_path_kd_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = ['121958', '131932', '259178', '365838', '671155'] #5 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = {}\n",
    "data_path['20ng'] = data_path_20ng\n",
    "data_path['wiki'] = data_path_wiki\n",
    "data_path['imdb'] = data_path_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = {}\n",
    "model_path['20ng_baseline'] = model_path_baseline_20ng\n",
    "model_path['wiki_baseline'] = model_path_baseline_wiki\n",
    "model_path['imdb_baseline'] = model_path_baseline_imdb\n",
    "model_path['20ng_kd'] = model_path_kd_20ng\n",
    "model_path['wiki_kd'] = model_path_kd_wiki\n",
    "model_path['imdb_kd'] = model_path_kd_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = {} #each data_model corresponding to a list of 5 betas for the five runs\n",
    "for data_model in model_path:\n",
    "    betas[data_model] = []\n",
    "    for seed in seeds:\n",
    "        betas[data_model].append(np.load(os.path.join(model_path[data_model], seed, 'beta.npz'))['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsd(p, q, base=np.e):\n",
    "    '''\n",
    "        Implementation of pairwise `jsd` based on  \n",
    "        https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence\n",
    "    '''\n",
    "    \n",
    "    ## normalize p, q to probabilities\n",
    "    p, q = np.array(torch.softmax(torch.from_numpy(p), dim=0)), np.array(torch.softmax(torch.from_numpy(q), dim=0))\n",
    "    m = (p + q)/2\n",
    "    return scipy.stats.entropy(p, m, base=base)/2. +  scipy.stats.entropy(q, m, base=base)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js_divergence(beta1, beta2):\n",
    "    assert beta1.shape==beta2.shape\n",
    "    x, y = beta1.shape\n",
    "    js_div_score_matrix = np.zeros((x,x))\n",
    "    for i in range(x):\n",
    "        for j in range(x):\n",
    "            js_div_score_matrix[i][j] = round(jsd(beta1[i], beta2[j]), 4)\n",
    "    return js_div_score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_matched_pairs(beta1, beta2):\n",
    "    assert beta1.shape==beta2.shape\n",
    "    js_div_scores = js_divergence(beta1, beta2)\n",
    "    #print(js_div_scores.shape)\n",
    "    topic_match_tuples = []\n",
    "    topic_match_scores = []\n",
    "    while len(topic_match_tuples)<50:\n",
    "        z = np.argmin(js_div_scores)\n",
    "        i = z//js_div_scores.shape[0]\n",
    "        j = z%js_div_scores.shape[1]\n",
    "        topic_match_tuples.append((i,j))\n",
    "        topic_match_scores.append(np.min(js_div_scores))\n",
    "        js_div_scores[i, :] = 2.0\n",
    "        js_div_scores[:, j] = 2.0\n",
    "    return topic_match_tuples, topic_match_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_topic_match_scores(data):\n",
    "    betas_baseline = betas[data+'_baseline']\n",
    "    betas_kd = betas[data+'_kd']\n",
    "    topic_match_scores = []\n",
    "    for x, y in zip(betas_baseline, betas_kd):\n",
    "        _, scores = get_topic_matched_pairs(x, y)\n",
    "        topic_match_scores.append(scores)\n",
    "    return np.mean(np.array(topic_match_scores), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_matched_scores = {}\n",
    "for data in data_path:\n",
    "    topic_matched_scores[data] = get_mean_topic_match_scores(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(topic_matched_scores['20ng'])==50\n",
    "assert len(topic_matched_scores['wiki'])==50\n",
    "assert len(topic_matched_scores['imdb'])==50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the inital graphs to make the judgements of threshold from\n",
    "x = list(range(1,51))\n",
    "for data in topic_matched_scores:\n",
    "    plt.plot(x, topic_matched_scores[data], '-')\n",
    "    plt.savefig(data + 'jsdiv_for_matched_topics.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after looking at the graphs\n",
    "thresholds = {}\n",
    "thresholds['20ng'] = 44\n",
    "thresholds['wiki'] = 44\n",
    "thresholds['imdb'] = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw with a vertical line to confirm thresholds\n",
    "x = list(range(1,51))\n",
    "for data in topic_matched_scores:\n",
    "    plt.plot(x, topic_matched_scores[data], '-')\n",
    "    plt.axvline(x=thresholds[data], linestyle='--')\n",
    "    plt.savefig('data + '_jsdiv_for_matched_topics_with_thresh_line.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce the plot with all three datasets in one that goes into the paper\n",
    "x = list(range(1,51))\n",
    "colors = {'20ng': 'r', 'wiki': 'b', 'imdb': 'g'}\n",
    "ls = {'20ng': 'solid', 'wiki': 'dashdot', 'imdb': 'dashed'}\n",
    "legend_map = {'20ng': '20NG', 'wiki': 'Wiki', 'imdb': 'IMDb'}\n",
    "xypos = {'20ng': (-1, 0.01), 'wiki': (-1, 0.015), 'imdb': (0, -0.04)}\n",
    "for data in topic_matched_scores:\n",
    "    y = topic_matched_scores[data]\n",
    "    thresh = thresholds[data]\n",
    "    plt.scatter(thresh,y[thresh-1], marker='|', color=colors[data])\n",
    "    plt.plot(x, y, color=colors[data], linestyle=ls[data], label=legend_map[data])\n",
    "    offset = xypos[data]\n",
    "    pos = (thresh + offset[0], y[thresh-1] + offset[1])\n",
    "    #plt.annotate(str(thresh), (thresh, y[thresh - 1]), ha='center', xytext=pos, color=colors[data])\n",
    "plt.xlabel('Matched Topic Pair (best to worst match)')\n",
    "plt.ylabel('JS Divergence Score')\n",
    "plt.legend()\n",
    "plt.xticks([0,10,20,30,40,44,50])\n",
    "plt.axvline(x=44, linestyle=(0, (1, 5)), color='black')\n",
    "plt.savefig('scholar_h2h-topic-pair_jsdiv-scores_final.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_npmi_vals_and_topic_words(ref_vocab, ref_counts, topics, n=10, cols_to_skip=0):\n",
    "    vocab_index = dict(zip(ref_vocab, range(len(ref_vocab))))\n",
    "    n_docs, _ = ref_counts.shape\n",
    "    npmi_values, top_words_strings = [], []\n",
    "    for topic in topics:\n",
    "        words = topic.strip().split()[cols_to_skip:]\n",
    "        npmi_vals = []\n",
    "        for word_i, word1 in enumerate(words[:n]):\n",
    "            if word1 in vocab_index:\n",
    "                index1 = vocab_index[word1]\n",
    "            else:\n",
    "                index1 = None\n",
    "            for word2 in words[word_i+1:n]:\n",
    "                if word2 in vocab_index:\n",
    "                    index2 = vocab_index[word2]\n",
    "                else:\n",
    "                    index2 = None\n",
    "                if index1 is None or index2 is None:\n",
    "                    npmi = 0.0\n",
    "                else:\n",
    "                    col1 = np.array((ref_counts[:, index1] > 0).todense(), dtype=int)\n",
    "                    col2 = np.array((ref_counts[:, index2] > 0).todense(), dtype=int)\n",
    "                    c1 = col1.sum()\n",
    "                    c2 = col2.sum()\n",
    "                    c12 = np.sum(col1 * col2)\n",
    "                    if c12 == 0:\n",
    "                        npmi = 0.0\n",
    "                    else:\n",
    "                        npmi = (np.log10(n_docs) + np.log10(c12) - np.log10(c1) - np.log10(c2)) / (np.log10(n_docs) - np.log10(c12))\n",
    "                npmi_vals.append(npmi)\n",
    "        npmi_values.append(round(np.mean(npmi_vals), 4))\n",
    "        top_words_strings.append(' '.join(words[:n]))\n",
    "    return npmi_values, top_words_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_npmi_topics(datapath, modelpath, n=10):\n",
    "    ref_vocab = fh.read_json(datapath + 'train.vocab.json')\n",
    "    ref_counts = fh.load_sparse(datapath + 'dev.npz').tocsc()\n",
    "    out = []\n",
    "    for seed in seeds:\n",
    "        topics = fh.read_text(modelpath + seed + '/topics.txt')\n",
    "        npmi_values, top_words_strings = get_npmi_vals_and_topic_words(ref_vocab, ref_counts, topics, n)\n",
    "#         top_words_lists = [x.split() for x in top_words_strings]\n",
    "#         top_words_strings = ['\\n'.join([' '.join(x[:3]), ' '.join(x[3:7]), ' '.join(x[7:])]) for x in top_words_lists]\n",
    "        out.append(list(zip(npmi_values, top_words_strings)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmi_topics = {}\n",
    "for model in model_path:\n",
    "    data, _ = model.split('_')\n",
    "    npmi_topics[model] = get_npmi_topics(data_path[data], model_path[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_baseline_kd_matched_topics(baseline_npmi_topics, kd_npmi_topics, topic_pairs_jsdiv_baseline_kd, top_matched_pairs=10):\n",
    "    kd_wins, baseline_wins = 0, 0\n",
    "    topic_pairs_jsdiv_baseline_kd = topic_pairs_jsdiv_baseline_kd[:top_matched_pairs]\n",
    "    for x in topic_pairs_jsdiv_baseline_kd:\n",
    "        #print('Baseline model NPMI and Topic:')\n",
    "        #print(baseline_npmi_topics[x[0]])\n",
    "        #print('KD model NPMI and Topic:')\n",
    "        #print(kd_npmi_topics[x[1]])\n",
    "        if baseline_npmi_topics[x[0]][0]>kd_npmi_topics[x[1]][0]:\n",
    "            baseline_wins+=1\n",
    "        else:\n",
    "            kd_wins+=1\n",
    "        #print('---')\n",
    "    return baseline_wins, kd_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kd_baseline_win_percentages = {}\n",
    "for data in data_path:\n",
    "    top_pairs_to_consider = thresholds[data]\n",
    "    all_kd_npmi_topics = npmi_topics[data + '_kd']\n",
    "    all_baseline_npmi_topics = npmi_topics[data + '_baseline']\n",
    "    all_baseline_wins, all_kd_wins = [], []\n",
    "    for i in range(len(seeds)):\n",
    "        beta_baseline = betas[data + '_baseline'][i]\n",
    "        beta_kd = betas[data + '_kd'][i]\n",
    "        baseline_npmi_topics = all_baseline_npmi_topics[i]\n",
    "        kd_npmi_topics = all_kd_npmi_topics[i]\n",
    "        topic_pairs_jsdiv_baseline_kd, _ = get_topic_matched_pairs(beta_baseline, beta_kd)\n",
    "        baseline_wins, kd_wins = compare_baseline_kd_matched_topics(baseline_npmi_topics, kd_npmi_topics, topic_pairs_jsdiv_baseline_kd, top_pairs_to_consider)\n",
    "        all_baseline_wins.append(baseline_wins)\n",
    "        all_kd_wins.append(kd_wins)\n",
    "    mean_kd_wins = np.mean(all_kd_wins)\n",
    "    mean_baseline_wins = np.mean(all_baseline_wins)\n",
    "    mean_kd_baseline_win_percentages[data] = (100*(mean_kd_wins/top_pairs_to_consider), 100*(mean_baseline_wins/top_pairs_to_consider))\n",
    "    print(data + ' DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_kd_baseline_wins = {}\n",
    "for data in data_path:\n",
    "    top_pairs_to_consider = thresholds[data]\n",
    "    all_kd_npmi_topics = npmi_topics[data + '_kd']\n",
    "    all_baseline_npmi_topics = npmi_topics[data + '_baseline']\n",
    "    all_baseline_wins, all_kd_wins = [], []\n",
    "    for i in range(len(seeds)):\n",
    "        beta_baseline = betas[data + '_baseline'][i]\n",
    "        beta_kd = betas[data + '_kd'][i]\n",
    "        baseline_npmi_topics = all_baseline_npmi_topics[i]\n",
    "        kd_npmi_topics = all_kd_npmi_topics[i]\n",
    "        topic_pairs_jsdiv_baseline_kd, _ = get_topic_matched_pairs(beta_baseline, beta_kd)\n",
    "        baseline_wins, kd_wins = compare_baseline_kd_matched_topics(baseline_npmi_topics, kd_npmi_topics, topic_pairs_jsdiv_baseline_kd, top_pairs_to_consider)\n",
    "        all_baseline_wins.append(baseline_wins)\n",
    "        all_kd_wins.append(kd_wins)\n",
    "    mean_kd_wins = np.mean(all_kd_wins)\n",
    "    mean_baseline_wins = np.mean(all_baseline_wins)\n",
    "    mean_kd_baseline_wins[data] = (mean_kd_wins, mean_baseline_wins)\n",
    "    print(data + ' DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in mean_kd_baseline_win_percentages:\n",
    "    l = list(mean_kd_baseline_win_percentages[x])\n",
    "    l2 = [round(z) for z in l]\n",
    "    mean_kd_baseline_win_percentages[x] = tuple(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barWidth = 0.3\n",
    "\n",
    "bars_baseline = [mean_kd_baseline_wins[x][1] for x in mean_kd_baseline_wins]\n",
    "bars_kd = [mean_kd_baseline_wins[x][0] for x in mean_kd_baseline_wins]\n",
    "\n",
    "r1 = np.arange(len(bars_baseline))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "plt.bar(r1, bars_baseline, color='#fdbb84', width=barWidth, edgecolor='black', label='SCHOLAR')\n",
    "plt.bar(r2, bars_kd, color='#e34a33', width=barWidth, edgecolor='black', label='SCHOLAR + OURMODEL')\n",
    "\n",
    "plt.xlabel('Dataset', fontweight='bold')\n",
    "plt.xticks([r + (barWidth/2) for r in range(len(bars_baseline))], ['20NG', 'Wiki', 'IMDb'])\n",
    "\n",
    "plt.ylabel('#Topics Better than Counterpart\\nin Matched Topic Pairs ', fontweight='bold')\n",
    "\n",
    "plt.ylim((0,44))\n",
    "plt.yticks([x for x in range(0,45,4)])\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('kd_baseline_wins_bars.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barWidth = 0.3\n",
    "\n",
    "# bars_baseline = [mean_kd_baseline_win_percentages[x][1] for x in mean_kd_baseline_win_percentages]\n",
    "# bars_kd = [mean_kd_baseline_win_percentages[x][0] for x in mean_kd_baseline_win_percentages]\n",
    "\n",
    "# r1 = np.arange(len(bars_baseline))\n",
    "# r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# plt.bar(r1, bars_baseline, color='#557f2d', width=barWidth, edgecolor='white', label='SCHOLAR')\n",
    "# plt.bar(r2, bars_kd, color='#2d7f5e', width=barWidth, edgecolor='white', label='SCHOLAR + OURMODEL')\n",
    "\n",
    "# plt.xlabel('Dataset', fontweight='bold')\n",
    "# plt.xticks([r + barWidth for r in range(len(bars_baseline))], ['20NG', 'Wiki', 'IMDb'])\n",
    "\n",
    "# plt.ylabel('% of Matched Topic Pairs', fontweight='bold')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.savefig('percent_kd_baseline_wins_bars.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_compare_baseline_kd_matched_topics(baseline_npmi_topics, kd_npmi_topics, topic_pairs_jsdiv_baseline_kd, scores, top_matched_pairs=10):\n",
    "    kd_wins, baseline_wins = 0, 0\n",
    "    topic_pairs_jsdiv_baseline_kd = topic_pairs_jsdiv_baseline_kd[:top_matched_pairs]\n",
    "    df = pd.DataFrame(columns=['Pair #', 'SCHOLAR vs SCHOLAR+BAT', 'JS Divergence'])\n",
    "    ind = list(range(1, top_pairs_to_consider+1))\n",
    "    b_k, js = [], []\n",
    "    for x, y in zip(topic_pairs_jsdiv_baseline_kd, scores):\n",
    "#         print('Baseline model NPMI and Topic:')\n",
    "#         print(baseline_npmi_topics[x[0]])\n",
    "#         #b.append(baseline_npmi_topics[x[0]])\n",
    "#         print('KD model NPMI and Topic:')\n",
    "#         print(kd_npmi_topics[x[1]])\n",
    "        #k.append(kd_npmi_topics[x[1]])\n",
    "        print('SCHOLAR: ' + str(baseline_npmi_topics[x[0]]) + '\\nSCHOLAR+BAT: ' + str(kd_npmi_topics[x[1]]))\n",
    "        b_k.append('SCHOLAR: ' + str(baseline_npmi_topics[x[0]]) + '\\nSCHOLAR+BAT: ' + str(kd_npmi_topics[x[1]]))\n",
    "        print('JS Div. Value = ' + str(y))\n",
    "        js.append(y)\n",
    "        if baseline_npmi_topics[x[0]][0]>kd_npmi_topics[x[1]][0]:\n",
    "            baseline_wins+=1\n",
    "        else:\n",
    "            kd_wins+=1\n",
    "        print('---')\n",
    "    df['Pair #'] = ind\n",
    "    #df['SCHOLAR'] = b\n",
    "    #df['SCHOLAR+BAT'] = k\n",
    "    df['SCHOLAR vs SCHOLAR+BAT'] = b_k\n",
    "    df['JS Divergence'] = js\n",
    "    return df, baseline_wins, kd_wins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20ng\n",
    "data = '20ng'\n",
    "top_pairs_to_consider = 50#thresholds[data]\n",
    "all_kd_npmi_topics = npmi_topics[data + '_kd']\n",
    "all_baseline_npmi_topics = npmi_topics[data + '_baseline']\n",
    "\n",
    "i = 2 #selecting a single seed\n",
    "\n",
    "beta_baseline = betas[data + '_baseline'][i]\n",
    "beta_kd = betas[data + '_kd'][i]\n",
    "baseline_npmi_topics = all_baseline_npmi_topics[i]\n",
    "kd_npmi_topics = all_kd_npmi_topics[i]\n",
    "topic_pairs_jsdiv_baseline_kd, scores = get_topic_matched_pairs(beta_baseline, beta_kd)\n",
    "df_20ng, baseline_wins, kd_wins = print_compare_baseline_kd_matched_topics(baseline_npmi_topics, kd_npmi_topics, topic_pairs_jsdiv_baseline_kd, scores, top_pairs_to_consider)\n",
    "\n",
    "print('KD Wins = ' + str(kd_wins))\n",
    "print('Baseline Wins = ' + str(baseline_wins))\n",
    "df_20ng.to_csv('20ng_topic_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki\n",
    "data = 'wiki'\n",
    "top_pairs_to_consider = 50#thresholds[data]\n",
    "all_kd_npmi_topics = npmi_topics[data + '_kd']\n",
    "all_baseline_npmi_topics = npmi_topics[data + '_baseline']\n",
    "\n",
    "i = 2 #selecting a single seed\n",
    "\n",
    "beta_baseline = betas[data + '_baseline'][i]\n",
    "beta_kd = betas[data + '_kd'][i]\n",
    "baseline_npmi_topics = all_baseline_npmi_topics[i]\n",
    "kd_npmi_topics = all_kd_npmi_topics[i]\n",
    "topic_pairs_jsdiv_baseline_kd, scores = get_topic_matched_pairs(beta_baseline, beta_kd)\n",
    "df_wiki, baseline_wins, kd_wins = print_compare_baseline_kd_matched_topics(baseline_npmi_topics, kd_npmi_topics, topic_pairs_jsdiv_baseline_kd, scores, top_pairs_to_consider)\n",
    "\n",
    "print('KD Wins = ' + str(kd_wins))\n",
    "print('Baseline Wins = ' + str(baseline_wins))\n",
    "df_wiki.to_csv('wiki_topic_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imdb\n",
    "data = 'imdb'\n",
    "top_pairs_to_consider = 50#thresholds[data]\n",
    "all_kd_npmi_topics = npmi_topics[data + '_kd']\n",
    "all_baseline_npmi_topics = npmi_topics[data + '_baseline']\n",
    "\n",
    "i = 2 #selecting a single seed\n",
    "\n",
    "beta_baseline = betas[data + '_baseline'][i]\n",
    "beta_kd = betas[data + '_kd'][i]\n",
    "baseline_npmi_topics = all_baseline_npmi_topics[i]\n",
    "kd_npmi_topics = all_kd_npmi_topics[i]\n",
    "topic_pairs_jsdiv_baseline_kd, scores = get_topic_matched_pairs(beta_baseline, beta_kd)\n",
    "df_imdb, baseline_wins, kd_wins = print_compare_baseline_kd_matched_topics(baseline_npmi_topics, kd_npmi_topics, topic_pairs_jsdiv_baseline_kd, scores, top_pairs_to_consider)\n",
    "\n",
    "print('KD Wins = ' + str(kd_wins))\n",
    "print('Baseline Wins = ' + str(baseline_wins))\n",
    "df_imdb.to_csv('imdb_topic_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(11,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(11,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(11,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(21,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(21,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(21,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(31,41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(31,41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(31,41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(41,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(41,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(41,51)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pg] *",
   "language": "python",
   "name": "conda-env-pg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
